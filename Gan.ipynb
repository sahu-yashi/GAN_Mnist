{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieyAWAFEYva3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "H7ThPSJyGjWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "zWNFBqvocSZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
        ")\n",
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)"
      ],
      "metadata": {
        "id": "kBhudYAde0yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "lr=3e-4\n",
        "img_size=28*28*1\n",
        "n_epoch=5\n",
        "noise=64"
      ],
      "metadata": {
        "id": "0uEPKA_lgzeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "iacacb33gVWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class discriminator(nn.Module):\n",
        "  def __init__(self,input_size):\n",
        "    super().__init__()\n",
        "    self.input_size=input_size\n",
        "    self.layer1=nn.Linear(input_size,128)\n",
        "    self.act1=nn.LeakyReLU(0.1)\n",
        "    self.layer2=nn.Linear(128,1)\n",
        "    self.act2=nn.Sigmoid()\n",
        "  def forward(self,X):\n",
        "    return self.act2(self.layer2(self.act1(self.layer1(X))))\n",
        "\n"
      ],
      "metadata": {
        "id": "_HPJf_eQZWwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class generator(nn.Module):\n",
        "  def __init__(self,input_size,mnist_dim):\n",
        "    super().__init__()\n",
        "    self.input_size=input_size\n",
        "    self.layer1=nn.Linear(input_size,256)\n",
        "    self.act1=nn.LeakyReLU(0.1)\n",
        "    self.layer2=nn.Linear(256,mnist_dim)\n",
        "    self.act2=nn.Tanh()\n",
        "  def forward(self,X):\n",
        "    return self.act2(self.layer2(self.act1(self.layer1(X))))\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "SZZnaENqa39A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc=discriminator(img_size).to(device)\n",
        "gen=generator(noise,img_size).to(device)\n",
        "disc_optim=optim.Adam(disc.parameters(),lr=lr)\n",
        "gen_optim=optim.Adam(gen.parameters(),lr=lr)\n",
        "criterion=nn.BCELoss()\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "writer_real = SummaryWriter(f\"logs/real\")"
      ],
      "metadata": {
        "id": "pBwwK2BzixwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps=len(loader)\n",
        "step=0\n",
        "for epoch in range(n_epoch):\n",
        "  for i ,(real,label) in enumerate(loader):\n",
        "    real=torch.flatten(real,start_dim=1).to(device)\n",
        "    batch_size=real.shape[0]\n",
        "    # creating real and fake labels\n",
        "    real_label=torch.ones(batch_size).to(device)\n",
        "    fake_label=torch.zeros(batch_size).to(device)\n",
        "    # output of dicriminator on real images\n",
        "    out_disc_real=disc.forward(real).reshape(batch_size)\n",
        "    # generating fake images\n",
        "    fake_noise=torch.randn(batch_size,noise).to(device)\n",
        "    fake=gen.forward(fake_noise)\n",
        "    # output of discriminator on fake images\n",
        "    out_disc_fake=disc.forward(fake).reshape(batch_size)\n",
        "    # discriminator loss \n",
        "    loss_disc_real=criterion(out_disc_real,real_label)\n",
        "    loss_disc_fake=criterion(out_disc_fake,fake_label)\n",
        "    total_Dloss=loss_disc_real+loss_disc_fake/2\n",
        "    # discriminator training\n",
        "    disc_optim.zero_grad()\n",
        "    total_Dloss.backward(retain_graph=True)\n",
        "    disc_optim.step()\n",
        "    # output of discriminator on fake images\n",
        "    out_disc_fake=disc.forward(fake).reshape(batch_size)\n",
        "    # generator loss\n",
        "    loss_gen=criterion(out_disc_fake,real_label)\n",
        "    # generator training\n",
        "    gen_optim.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    gen_optim.step()\n",
        "\n",
        "\n",
        "    # tensorboard\n",
        "    if i == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{n_epoch}] Batch {i}/{len(loader)} \\\n",
        "                      Loss D: {total_Dloss:.4f}, loss G: {loss_gen:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fake_noise).reshape(-1, 1, 28, 28)\n",
        "                data = real.reshape(-1, 1, 28, 28)\n",
        "                \n",
        "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
        "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
        "\n",
        "\n",
        "                writer_fake.add_image(\n",
        "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
        "                )\n",
        "                writer_real.add_image(\n",
        "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
        "                )\n",
        "                step += 1\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztYY_th_labG",
        "outputId": "2db3b354-821e-4843-90a1-4ca593fcb849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/5] Batch 0/1875                       Loss D: 1.0057, loss G: 0.7209\n",
            "Epoch [1/5] Batch 0/1875                       Loss D: 0.3974, loss G: 1.1634\n",
            "Epoch [2/5] Batch 0/1875                       Loss D: 0.6470, loss G: 1.0462\n",
            "Epoch [3/5] Batch 0/1875                       Loss D: 1.1294, loss G: 0.4322\n",
            "Epoch [4/5] Batch 0/1875                       Loss D: 0.8507, loss G: 0.5516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hISDrGfd1aK3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}